import os, re
import glob
import shutil
import pandas as pd

##############################
# CONFIG
# can be overwritten by using --configfile <path to config> when calling snakemake
# configfile:"config/config.yaml"

include:
    "rules/init.smk"


rule assembly:
    input:
        expand(os.path.join(RESULTS_DIR, "assemblies/flye_pre.fasta")),
        expand(os.path.join(RESULTS_DIR, "assemblies/raven_pre.fasta")),
        os.path.join(RESULTS_DIR, "stats/stats_assemblies.txt"),
        expand(os.path.join(RESULTS_DIR, "assemblies/{assembly}_clean.fasta"), assembly = ["flye", "raven"]),
        expand(os.path.join(RESULTS_DIR, "annotations/{assembly}"), assembly = ["flye", "raven"]),
        os.path.join(RESULTS_DIR,"checkm2/quality_report.tsv"),
        os.path.join(RESULTS_DIR,"best_assembly.txt")


rule concatenate_reads:
	input:
		expand(os.path.join(READS_DIR, "{reads}.fastq.gz"), reads = READS)
	output:
		temp(os.path.join(RESULTS_DIR, "rawReads/concatenated_reads.fastq.gz"))
    # localrule: True
	shell:
		"cat {input} > {output}"


# rule filter_fitlong:
#     input:
#         rules.concatenate_reads.output
#     output:
#         temp(os.path.join(RESULTS_DIR, "filteredReads/filtered_reads.fastq"))
#     conda:
#         os.path.join(ENV_DIR, "filter_reads.yaml")
#     params:
#         reads_size = config["reads_size"]
#     log:
#         out=os.path.join(RESULTS_DIR, "logs/filter.out.log"),
#         err=os.path.join(RESULTS_DIR, "logs/filter.err.log")
#     shell:
#         "(date && filtlong --min_length {params.reads_size} --keep_percent 90 {input} > {output} && date) 2> {log.err} > {log.out}"

rule filter_porechop:
    input:
        reads=rules.concatenate_reads.output
    output:
        temp(os.path.join(RESULTS_DIR, "filteredReads/filtered_reads_adapter_trimmed.fastq.gz")),
    log:
        os.path.join(RESULTS_DIR, "logs/filter_porechop.log")
    conda:
        os.path.join(ENV_DIR, "filter_reads.yaml")
    threads: 15
    shell:
        """
        (date && porechop -i {input.reads} -o {output} -t {threads}) &> {log}
        """

rule filter_chopper:
    input:
        reads=rules.filter_porechop.output
    output:
        temp(os.path.join(RESULTS_DIR, "filteredReads/filtered_reads_chopper.fastq.gz"))
    log:
        os.path.join(RESULTS_DIR, "logs/filter_chopper.log")
    conda:
        os.path.join(ENV_DIR, "filter_reads.yaml")
    params:
        reads_size = config["reads_size"]
    threads: 15
    shell:
        """
        (date && chopper -q 10 -l {params.reads_size} -i {input.reads} --threads {threads} | pigz -p {threads} > {output} ) &> {log}
        """

rule flye:
    input:
        rules.filter_chopper.output
    output:
        folder = temp(directory(os.path.join(RESULTS_DIR, "flye/sample"))),
        fasta = os.path.join(RESULTS_DIR, "assemblies/flye_pre.fasta")
    conda:
        os.path.join(ENV_DIR, "flye.yaml")
    resources:
        time = "05:00:00"
    log:
        out=os.path.join(RESULTS_DIR, "logs/flye.out.log"),
        err=os.path.join(RESULTS_DIR, "logs/flye.err.log")
    threads: 16
    shell:
        """
        (date && flye --nano-raw {input} --out-dir {output.folder} --threads {threads} && 
        cp {output.folder}/assembly.fasta {output.fasta} && 
        date) 2> {log.err} > {log.out}
        """

rule raven:
    input:
        rules.filter_chopper.output
    output:
        fasta=os.path.join(RESULTS_DIR, "assemblies/raven_pre.fasta")
    log:
        out=os.path.join(RESULTS_DIR, "logs/raven.out.log"),
        err=os.path.join(RESULTS_DIR, "logs/raven.err.log")
    resources:
        time = "03:00:00"
    conda:
        os.path.join(ENV_DIR, "raven.yaml")
    threads: 8
    shell:
        "(date && raven --threads 8 --disable-checkpoints {input} > {output.fasta} && date) 2> {log.err} > {log.out}"


rule medaka:
    input:
        fasta=os.path.join(RESULTS_DIR, "assemblies/{assembly}_pre.fasta"),
        reads=rules.filter_chopper.output
    output:
        fasta = os.path.join(RESULTS_DIR, "assemblies/{assembly}_clean.fasta"),
        folder = temp(directory(os.path.join(RESULTS_DIR, "assemblies/{assembly}_medaka")))
    conda:
        os.path.join(ENV_DIR, "medaka.yaml")
    resources:
        time = "01:00:00",
        memory = "50G"
    log:
        out=os.path.join(RESULTS_DIR, "logs/medaka_{assembly}.out.log"),
        err=os.path.join(RESULTS_DIR, "logs/medaka_{assembly}.err.log")
    threads: 10
    shell:
        "(date && "
        "medaka_consensus -x -i {input.reads} -d {input.fasta} -o {output.folder} -t {threads} && cp {output.folder}/consensus.fasta {output.fasta} && date) 2> {log.err} > {log.out}"

# rule ragtag:
#     input:
#         raven =  os.path.join(RESULTS_DIR, "assemblies/raven_clean.fasta"),
#         flye = os.path.join(RESULTS_DIR, "assemblies/flye_clean.fasta")
#     output:
#         raven= os.path.join(RESULTS_DIR, "assemblies_merge/raven_clean.fasta"),
#         flye = os.path.join(RESULTS_DIR, "assemblies_merge/flye_clean.fasta")
#     conda:
#         os.path.join(ENV_DIR, "ragtag.yaml")
#     threads: 2
#     resources:
#         time = "01:00:00"
#     log:
#         out=os.path.join(RESULTS_DIR, "logs/ragtag.out.log"),
#         err=os.path.join(RESULTS_DIR, "logs/ragtag.err.log")
#     shell:
#         """
#        (date && 
#        ragtag.py scaffold -u -o $(dirname {input.raven})/raven {input.flye} {input.raven} && 
#        ragtag.py scaffold -u -o $(dirname {input.raven})/flye {input.raven} {input.flye} &&
#        cp $(dirname {input.raven})/raven/ragtag.scaffold.fasta {output.raven} && 
#        cp $(dirname {input.raven})/flye/ragtag.scaffold.fasta {output.flye} && 
#        date ) 2> {log.err} > {log.out}
#        """


rule getStats:
    input:
        raven = os.path.join(RESULTS_DIR, "assemblies/raven_clean.fasta"),
        flye = os.path.join(RESULTS_DIR, "assemblies/flye_clean.fasta")
    output:
        os.path.join(RESULTS_DIR, "stats/stats_assemblies.txt")
    conda:
        os.path.join(ENV_DIR, "seqkit.yaml")
    threads: 1
    shell:
        "seqkit stats -T -a {input.raven} {input.flye} > {output}"

rule bakta:
    input:
        os.path.join(RESULTS_DIR,"assemblies/{assembly}_clean.fasta")
    output:
        directory(os.path.join(RESULTS_DIR, "annotations/{assembly}"))
    conda:
        os.path.join(ENV_DIR, "bakta.yaml")
    params:
        config["bakta_db"]
    threads:
        10
    resources:
        time = "02:00:00"
    log:
        out=os.path.join(RESULTS_DIR, "logs/bakta_{assembly}.out.log"),
        err=os.path.join(RESULTS_DIR, "logs/bakta_{assembly}.err.log")
    shell:
        "(date && bakta --db {params} --output {output} --keep-contig-headers --compliant --threads {threads} --force {input} && date) 2> {log.err} > {log.out}"


rule checkm2:
    input:
        expand(os.path.join(RESULTS_DIR,"assemblies/{assembly}_clean.fasta"), assembly = ["raven", "flye"])
    output:
        os.path.join(RESULTS_DIR,"checkm2/quality_report.tsv")
    conda:
        os.path.join(ENV_DIR, "checkm2.yaml")
    params:
        config["checkm2_db"]
    threads:
        10
    resources:
        time = "02:00:00"
    log:
        out=os.path.join(RESULTS_DIR, "logs/checkm2.out.log"),
        err=os.path.join(RESULTS_DIR, "logs/checkm2.err.log")
    shell:
        "(date && checkm2 predict --force --database_path {params} --output-directory $(dirname {output}) --threads {threads} --input {input} && date) 2> {log.err} > {log.out}"

rule find_best_assembly:
    input:
        checkm2=rules.checkm2.output,
        seqkit=rules.getStats.output
    output:
        os.path.join(RESULTS_DIR,"best_assembly.txt")
    localrule: True
    run:
        import polars as pl
        import re

        checkm2 = pl.read_csv(input[0], separator="\t")
        seqkit = pl.read_csv(input[1], separator="\t")

        seqkit = pl.read_csv("stats_assemblies.txt", separator = "\t")

        diff_comp = max(checkm2['Completeness'])-min(checkm2['Completeness'])
        diff_contamination = max(checkm2['Contamination'])-min(checkm2['Contamination'])

        genome_comp = max(checkm2['Completeness'])
        genome_contamination = min(checkm2['Contamination'])
        genome_size = max(checkm2['Genome_Size'])

        seqkit = seqkit.with_columns([pl.col('file').str.extract(r'.*\/(.*).fasta').alias('Name')])

        diff_contig = max(seqkit['num_seqs'])-min(seqkit['num_seqs'])

        min_contig = min(seqkit['num_seqs'])
        min_contig_name = seqkit.filter(pl.col('num_seqs') == min_contig)['Name'][0]

        merged_df = checkm2.join(seqkit, on='Name', how='inner')

        columns_to_keep = ['Name','Completeness','Contamination',
                        'Genome_Size','num_seqs','Contig_N50',
                        'GC_Content']

        merged_df = merged_df.select(columns_to_keep)
        merged_df = merged_df.rename({'num_seqs': 'Number_of_Contigs'})

        if diff_comp >= 5:
            final = merged_df.filter(pl.col('Completeness') == genome_comp)[0]
        elif diff_contamination >= 1:
            final = merged_df.filter(pl.col('Contamination') == genome_contamination)[0]
        elif diff_contig > 0:
            final = merged_df.filter(pl.col('Name') == min_contig_name)
        else:
            final = merged_df.filter(pl.col('Genome_Size') == genome_size)  

        final.write_csv(output[0], separator="\t")

